{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./Data/File1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date the bundle was purchased\n",
    "purchased_dt = pd.to_datetime('10/24/2008')\n",
    "\n",
    "# Calculate the days until Out of Statute\n",
    "df['OOS Days Left'] = df['OOS Date'] - purchased_dt\n",
    "df['OOS Days Left int'] = 0\n",
    "\n",
    "for i, _ in df.iterrows():\n",
    "    days = df.iloc[i]['OOS Days Left'].days\n",
    "    df.iloc[i,29] = days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Account Number', 'PortID', 'Remaining Balance', 'interests Fees',\n",
       "       'Date Opened', 'Charge Off Date', 'Last Pay Date', 'Last Pay Amount',\n",
       "       'Last Activity Date', 'Interest Rate %', 'Issuer', 'Merchant',\n",
       "       'FCFRA Date', 'OOS Date', 'Account Type', 'Last Name', 'First Name',\n",
       "       'Middle Name', 'Address', 'City', 'State', 'Zip', 'County', 'SSN',\n",
       "       'Home Phone', 'Employer Phone', 'Paid', 'OOS Days Left',\n",
       "       'OOS Days Left int', 'Cycle_QUATERNARY', 'Cycle_SECONDARY',\n",
       "       'Cycle_TERTIARY'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy up the Cycle as this is an important feature\n",
    "df = pd.get_dummies(df, columns = ['Cycle'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the new .csv file\n",
    "df.to_csv(\"./Data/cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.columns[[np.issubdtype(dt, np.number) for dt in df.dtypes]]\n",
    "\n",
    "drop_cols = [key for key in dict(df.dtypes) \n",
    "                if dict(df.dtypes)[key] in ['datetime64[ns]', 'object']]\n",
    "\n",
    "# Add others to drop list\n",
    "drop_cols.extend(('Paid','Account Number','SSN','Home Phone',\n",
    "                  'Employer Phone','OOS Days Left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Paid']\n",
    "X = df.drop(columns = drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = ss.transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and making predictions with the Logistic Regression model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Instantiate our model.\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Step 2: Fit our model.\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print('Logreg intercept:', logreg.intercept_)\n",
    "print('Logreg coef(s):', logreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Logreg predicted:', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix Evaluation Metrics\n",
    "Let's evaluate the model using model evaluation metrics such as accuracy, precision, and recall.\n",
    "\n",
    "- Well, you got a classification rate of 76%, considered as ok accuracy.\n",
    "\n",
    "- Precision: Precision is about being precise, i.e., how accurate your model is. In other words, you can say, when a model makes a prediction, how often it is correct. In your prediction case, when your Logistic Regression model predicted debtors will pay back 0%, of the time.\n",
    "\n",
    "- Recall: If there are debtors who pay back in the test set and your Logistic Regression model can identify it 0% of the time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve\n",
    "Receiver Operating Characteristic(ROC) curve is a plot of the true positive rate against the false positive rate. It shows the tradeoff between sensitivity and specificity.\n",
    "\n",
    "- AUC score for the case is 0.36. AUC score 1 represents perfect classifier, and 0.4 represents a worthless classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and making predictions with DecisionTreeClassifier model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion: splitting decision function, can be 'gini' or 'entropy'\n",
    "# max_depth: the maximum number of hierarchical decision nodes(how \"deep\" the tree is \n",
    "# built)\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion='gini',\n",
    "                                    max_depth=None)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# decision trees can give us feature importances. the higher the number the more important\n",
    "# the predictor was to deciding splits at nodes.\n",
    "# \"The importance of a feature is computed as the (normalized) total reduction of the \n",
    "# criterion brought by that feature.\"\n",
    "#\n",
    "feature_importances = classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = list(zip(classifier.feature_importances_, X.columns))\n",
    "importances.sort(reverse=True)\n",
    "\n",
    "pd.DataFrame(importances, index=[x for (_,x) in importances]).plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and making predictions with RandomForestClassifier model.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "classifier=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "# prediction on test set\n",
    "y_pred=classifier.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = list(zip(classifier.feature_importances_, X.columns))\n",
    "importances.sort(reverse=True)\n",
    "\n",
    "pd.DataFrame(importances, index=[x for (_,x) in importances]).plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and making predictions with XGBoost model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "print(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and making predictions with KNeighborsClassifier model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate KNN\n",
    "\n",
    "For the `KNeighborsClassifier`, there a few important parameters to keep in mind:\n",
    "\n",
    "1. `n_neighbors`: this is the \"K\" in KNN. The best K will change from problem to problem, but the default is 5.\n",
    "2. `weights`: The neighbors can all have an equal vote (`uniform`), or the closer points can have a higher weighted vote (`distance`).\n",
    "3. `p`: The distance metric. The default is Euclidean distance (2). Changing it to 1 is setting the distance to Manhattan.\n",
    "\n",
    "In the cell below, instantiate a `knn` model using the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because these are dummy vaiables scaling is not required\n",
    "features = ['Cycle_QUATERNARY', 'Cycle_SECONDARY', 'Cycle_TERTIARY']\n",
    "X_knn = df[features]\n",
    "y_knn = df['Paid']\n",
    "\n",
    "# Split dataset into training set and test set 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_knn, y_knn, test_size=0.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation\n",
    "\n",
    "In the cell below, use `cross_val_score` to see what accuracy we can expect from our KNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(knn, X_train, y_train).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and making predictions using Neural Networks with Keras Binary Classifier\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)\n",
    "y_train = y_train*-1 + 1\n",
    "y_test = y_test*-1 + 1\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = ss.transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "n_input = X_train.shape[1]\n",
    "n_hidden = n_input\n",
    "\n",
    "model.add(Dense(n_hidden, input_dim=n_input, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "              epochs=10000, batch_size=None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(test_loss, label='Testing loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df = pd.DataFrame()\n",
    "\n",
    "# paid = y\n",
    "# paid.replace({1 :'yes', 0 : 'no'}, inplace=True)\n",
    "# pred_df['paid'] = paid\n",
    "\n",
    "# y_pred = pd.DataFrame(y_pred.reshape(len(y_pred), -1))\n",
    "# pred_df['y_pred'] = y_pred\n",
    "\n",
    "# pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
